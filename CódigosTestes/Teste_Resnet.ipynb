{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp0gEduVL3Gj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications import ResNet50\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/Projeto_Pneumonia/chest_xray/train\"\n",
        "test_dir = \"/content/drive/MyDrive/Projeto_Pneumonia/chest_xray/test\"\n",
        "val_dir = \"/content/drive/MyDrive/Projeto_Pneumonia/chest_xray/val\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teBqfU2CL8yk",
        "outputId": "c4bbe419-8ed5-47e9-e2da-ced447c15997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gerador de imagens pré-processamento\n",
        "image_generator = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    samplewise_center=True,\n",
        "    samplewise_std_normalization=True\n",
        ")"
      ],
      "metadata": {
        "id": "MU635dybMIGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gerador dados treinamento e validação\n",
        "train_generator = image_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    class_mode='binary',\n",
        "    target_size=(180, 180)\n",
        ")\n",
        "\n",
        "validation_generator = image_generator.flow_from_directory(\n",
        "    val_dir,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    class_mode='binary',\n",
        "    target_size=(180, 180)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYKyaVmHMXbp",
        "outputId": "34cb35f7-0544-4f57-e4a6-3bdc488eacd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5218 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resnet\n",
        "resnet_base_model = ResNet50(\n",
        "    input_shape=(180, 180, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2N_0oaYMu3v",
        "outputId": "22a0be09-9966-48d7-8b18-bdffbc0baaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Camadas personalizadas\n",
        "resnet_model = tf.keras.Sequential([\n",
        "    resnet_base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.6),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "iVYwm8qOM39p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compilando Resnet\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "METRICS = [\n",
        "    'accuracy',\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall'),\n",
        "]\n",
        "resnet_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=METRICS)"
      ],
      "metadata": {
        "id": "MH9tTsgANDbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando modelo\n",
        "\n",
        "# Calcular o peso das classes com base na contagem\n",
        "num_normal = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\n",
        "num_pneumonia = len(os.listdir(os.path.join(train_dir, 'PNEUMONIA')))\n",
        "\n",
        "weight_for_0 = num_pneumonia / (num_normal + num_pneumonia)\n",
        "weight_for_1 = num_normal / (num_normal + num_pneumonia)\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "history = resnet_model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    class_weight=class_weight,\n",
        "    steps_per_epoch=100,\n",
        "    validation_steps=25\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFC7nCbXNYKF",
        "outputId": "acc1d8f4-c433-45fe-cf55-3bc8fd8de22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3096 - accuracy: 0.5970 - precision: 0.8239 - recall: 0.5889"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 25 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 545s 5s/step - loss: 0.3096 - accuracy: 0.5970 - precision: 0.8239 - recall: 0.5889 - val_loss: 881.4910 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 473s 5s/step - loss: 0.3472 - accuracy: 0.5025 - precision: 0.7366 - recall: 0.5127\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 476s 5s/step - loss: 0.2964 - accuracy: 0.5612 - precision: 0.7837 - recall: 0.5554\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 476s 5s/step - loss: 0.2939 - accuracy: 0.5663 - precision: 0.7603 - recall: 0.5791\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 482s 5s/step - loss: 0.2762 - accuracy: 0.5550 - precision: 0.8053 - recall: 0.5204\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 482s 5s/step - loss: 0.2249 - accuracy: 0.6700 - precision: 0.9050 - recall: 0.6298\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 477s 5s/step - loss: 0.1926 - accuracy: 0.7613 - precision: 0.9146 - recall: 0.7513\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 474s 5s/step - loss: 0.1727 - accuracy: 0.7950 - precision: 0.9525 - recall: 0.7746\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 476s 5s/step - loss: 0.1736 - accuracy: 0.8138 - precision: 0.9371 - recall: 0.8030\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 476s 5s/step - loss: 0.1484 - accuracy: 0.8313 - precision: 0.9520 - recall: 0.8109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = history.history['loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "train_precision = history.history['precision']\n",
        "train_recall = history.history['recall']\n",
        "\n",
        "val_loss = history.history['val_loss']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "val_precision = history.history['val_precision']\n",
        "val_recall = history.history['val_recall']\n",
        "\n",
        "print(\"Métricas de Treinamento:\")\n",
        "print(f\"Loss: {train_loss[-1]:.4f}\")\n",
        "print(f\"Acurácia: {train_accuracy[-1] * 100:.2f}%\")\n",
        "print(f\"Precisão: {train_precision[-1] * 100:.2f}%\")\n",
        "print(f\"Recall: {train_recall[-1] * 100:.2f}%\")\n",
        "\n",
        "print(\"\\nMétricas de Validação:\")\n",
        "print(f\"Loss: {val_loss[-1]:.4f}\")\n",
        "print(f\"Acurácia: {val_accuracy[-1] * 100:.2f}%\")\n",
        "print(f\"Precisão: {val_precision[-1] * 100:.2f}%\")\n",
        "print(f\"Recall: {val_recall[-1] * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHWOwS6lNcfr",
        "outputId": "9a0eace6-55b1-4c8e-97bf-fc0b2563f34e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métricas de Treinamento:\n",
            "Loss: 0.1484\n",
            "Acurácia: 83.13%\n",
            "Precisão: 95.20%\n",
            "Recall: 81.09%\n",
            "\n",
            "Métricas de Validação:\n",
            "Loss: 881.4910\n",
            "Acurácia: 50.00%\n",
            "Precisão: 0.00%\n",
            "Recall: 0.00%\n"
          ]
        }
      ]
    }
  ]
}