{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gp0gEduVL3Gj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications import ResNet50\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/Projeto_Pneumonia/chest_xray/train\"\n",
        "test_dir = \"/content/drive/MyDrive/Projeto_Pneumonia/chest_xray/test\"\n",
        "val_dir = \"/content/drive/MyDrive/Projeto_Pneumonia/chest_xray/val\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teBqfU2CL8yk",
        "outputId": "4c446af7-ff5c-4ef6-eb0b-b17394be5c4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gerador de imagens pré-processamento\n",
        "image_generator = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    samplewise_center=True,\n",
        "    samplewise_std_normalization=True\n",
        ")"
      ],
      "metadata": {
        "id": "MU635dybMIGU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gerador dados treinamento e validação\n",
        "train_generator = image_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    class_mode='binary',\n",
        "    target_size=(180, 180)\n",
        ")\n",
        "\n",
        "validation_generator = image_generator.flow_from_directory(\n",
        "    val_dir,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    class_mode='binary',\n",
        "    target_size=(180, 180)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYKyaVmHMXbp",
        "outputId": "02760296-7423-4373-84af-32df9c9b378c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5218 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resnet\n",
        "resnet_base_model = ResNet50(\n",
        "    input_shape=(180, 180, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2N_0oaYMu3v",
        "outputId": "bd392859-b2d3-435a-b78a-34324ef953cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Camadas personalizadas\n",
        "resnet_model = tf.keras.Sequential([\n",
        "    resnet_base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.6),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "iVYwm8qOM39p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compilando Resnet\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "METRICS = [\n",
        "    'accuracy',\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall'),\n",
        "]\n",
        "resnet_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=METRICS)"
      ],
      "metadata": {
        "id": "MH9tTsgANDbf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando modelo\n",
        "\n",
        "# Calcular o peso das classes com base na contagem\n",
        "num_normal = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\n",
        "num_pneumonia = len(os.listdir(os.path.join(train_dir, 'PNEUMONIA')))\n",
        "\n",
        "weight_for_0 = num_pneumonia / (num_normal + num_pneumonia)\n",
        "weight_for_1 = num_normal / (num_normal + num_pneumonia)\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "history = resnet_model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    class_weight=class_weight,\n",
        "    steps_per_epoch=100,\n",
        "    validation_steps=25\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFC7nCbXNYKF",
        "outputId": "99cc6e02-8421-4f38-8c81-07b415949d81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.5700 - precision: 0.8093 - recall: 0.5705"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 25 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 594s 6s/step - loss: 0.3000 - accuracy: 0.5700 - precision: 0.8093 - recall: 0.5705 - val_loss: 1.2056 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 491s 5s/step - loss: 0.2499 - accuracy: 0.6725 - precision: 0.8638 - recall: 0.6582\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 484s 5s/step - loss: 0.2220 - accuracy: 0.6888 - precision: 0.9005 - recall: 0.6600\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 487s 5s/step - loss: 0.2108 - accuracy: 0.7163 - precision: 0.8904 - recall: 0.6964\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 489s 5s/step - loss: 0.1865 - accuracy: 0.7513 - precision: 0.9304 - recall: 0.7265\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 493s 5s/step - loss: 0.2101 - accuracy: 0.7075 - precision: 0.8973 - recall: 0.6982\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 495s 5s/step - loss: 0.2071 - accuracy: 0.7237 - precision: 0.8966 - recall: 0.7063\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 487s 5s/step - loss: 0.2021 - accuracy: 0.6888 - precision: 0.9089 - recall: 0.6494\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 488s 5s/step - loss: 0.1772 - accuracy: 0.7513 - precision: 0.9397 - recall: 0.7267\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 487s 5s/step - loss: 0.1649 - accuracy: 0.7775 - precision: 0.9350 - recall: 0.7521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas para treinamento\n",
        "train_metrics = resnet_model.evaluate(train_generator, steps=len(train_generator))\n",
        "train_loss, train_accuracy, train_precision, train_recall = train_metrics\n",
        "\n",
        "# Métricas para validação\n",
        "val_metrics = resnet_model.evaluate(validation_generator, steps=len(validation_generator))\n",
        "val_loss, val_accuracy, val_precision, val_recall = val_metrics\n",
        "\n",
        "# Calcular F1 Score manualmente para treinamento\n",
        "f1_train = 2 * (train_precision * train_recall) / (train_precision + train_recall)\n",
        "\n",
        "# Calcular F1 Score manualmente para validação\n",
        "f1_val = 2 * (val_precision * val_recall) / (val_precision + val_recall)\n",
        "\n",
        "# Exibir métricas\n",
        "print(\"Métricas de Treinamento:\")\n",
        "print(f\"Loss: {train_loss:.4f}\")\n",
        "print(f\"Acurácia: {train_accuracy * 100:.2f}%\")\n",
        "print(f\"Precisão: {train_precision * 100:.2f}%\")\n",
        "print(f\"Recall: {train_recall * 100:.2f}%\")\n",
        "print(f\"F1 Score (Treinamento): {f1_train * 100:.2f}%\")\n",
        "\n",
        "print(\"\\nMétricas de Validação:\")\n",
        "print(f\"Loss: {val_loss:.4f}\")\n",
        "print(f\"Acurácia: {val_accuracy * 100:.2f}%\")\n",
        "print(f\"Precisão: {val_precision * 100:.2f}%\")\n",
        "print(f\"Recall: {val_recall * 100:.2f}%\")\n",
        "print(f\"F1 Score (Validação): {f1_val * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHWOwS6lNcfr",
        "outputId": "f91b92a2-fb9b-4add-b0ae-663b0995e277"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "653/653 [==============================] - 798s 1s/step - loss: 0.5980 - accuracy: 0.7928 - precision: 0.9701 - recall: 0.7441\n",
            "16/16 [==============================] - 3s 155ms/step - loss: 0.8979 - accuracy: 0.6250 - precision: 0.5714 - recall: 1.0000\n",
            "Métricas de Treinamento:\n",
            "Loss: 0.5980\n",
            "Acurácia: 79.28%\n",
            "Precisão: 97.01%\n",
            "Recall: 74.41%\n",
            "F1 Score (Treinamento): 84.22%\n",
            "\n",
            "Métricas de Validação:\n",
            "Loss: 0.8979\n",
            "Acurácia: 62.50%\n",
            "Precisão: 57.14%\n",
            "Recall: 100.00%\n",
            "F1 Score (Validação): 72.73%\n"
          ]
        }
      ]
    }
  ]
}